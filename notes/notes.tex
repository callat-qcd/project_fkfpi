\documentclass[prd,tightenlines,preprintnumbers,showpacs,superscriptaddress,notitlepage,eqsecnum,floatfix,notitlepage]{revtex4-1}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{braket}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{float}
\usepackage[utf8]{inputenc} % supports umlaut natively, eg
%\usepackage[T1]{fontenc}
\usepackage{hyperref} % adds hyperlinks
\usepackage{csvsimple} % Easily add csv file as table
\usepackage{booktabs} % For pretty tables
\usepackage{siunitx} % For rounding in tables
\usepackage{datatool}
\usepackage{url}
\usepackage{multirow}
\newcount\hour \newcount\hourminute \newcount\minute
\hour=\time \divide \hour by 60
\hourminute=\hour \multiply \hourminute by 60
\minute=\time \advance \minute by -\hourminute
\newcommand{\mydate}{\ \today \ - \number\hour :\number\minute}
\newcommand{\includegraphicsifexists}[2][]{\IfFileExists{#2}{\includegraphics[draft=false, #1]{#2}}{\includegraphics[draft=true, #1]{#2}}}

\raggedbottom

\begin{document}

\title{$F_K / F_\pi$ Notes}
\author{Nolan Miller}
\date{\mydate}


\begin{abstract}
In these notes, we explain our general fitting strategy for determining $F_K / F_\pi$. The description of the fit functions is mostly plagiarized from André's notes (though edited some for clarity), so kudos to him.
\end{abstract}
\maketitle

\section{Background}
\subsection{Connection to the CKM Metrix}
The Cabibbo–Kobayashi–Maskawa (CKM) matrix characterizes the extent to which the quarks eigenstates of the strong interaction can be thought of as a quark eigenstates of the weak interaction. In a universe where the quark eigenstates of the weak and strong interaction are the same, the CKM matrix is the identity; we are evidently not in that universe (quarks can change flavors through the weak interaction), and indeed the CKM matrix reflects that deviation from the identity. Per the PDG \cite{PhysRevD.98.030001} (and slightly overestimating some uncertainties for notational simplicity),
\begin{equation}
\begin{bmatrix}
|V_{ud}| & |V_{us}| & |V_{ub}| \\
|V_{cd}| & |V_{cs}| & |V_{cb}| \\
|V_{td}| & |V_{ts}| & |V_{tb}|
\end{bmatrix} = \begin{bmatrix}
0.97446(10) & 0.22452(44) & 0.00365(12) \\
0.22438(44) & 0.97359(11) & 0.04214(76) \\
0.00896(24) & 0.04133(74) & 0.999105(32)
\end{bmatrix}.
\end{equation}

\begin{figure}
	\includegraphicsifexists[width=0.4\textwidth]{./../figs/kaon_box_diagram.png}
	\caption{A kaon box diagram  (taken from Wikipedia). Because the quark eigenstates are different in the strong and weak interactions, a $K^0$ can spontaneously change into a $\overline{K}^0$. Consequently, kaon decays do not conserve CP.}
\end{figure}

Since the standard model predicts the CKM matrix is unitary, for quarks of a given generation $i$ we expect $\sum_k |V_{ik}|^2 = 1$. In particular,
\begin{equation}
|V_{ud}|^2 + |V_{us}|^2 + |V_{ub}|^2 = 1 \, .
\end{equation} 
The matrix element $|V_{us}|$ is well-known from experiment; the matrix element $|V_{ub}|$ is small compared to the others. Therefore, $|V_{us}|$ is important for determining unitarity. Additionally, in the Wolfenstein  $(\lambda, A, \overline{\rho}, \overline{\eta})$ parameterization of the CKM matrix \cite{Wolfenstein:1983yz}, $|V_{us}| = \lambda$ and thus affects all the other entries of the CKM matrix.

Marciano \cite{Marciano:2004uf, Durr:2010hr} showed how one can calculate this matrix element from the ratio of the leptonic decay constants and $|V_{ud}|^2$.
\begin{equation}
\frac{\Gamma(K \rightarrow l \, \overline{\nu}_l)}{\Gamma(\pi \rightarrow l \, \overline{\nu}_l)} =
\left(\frac{F_K}{F_\pi} \right)^2 \frac{|V_{us}|^2}{|V_{ud}|^2} \frac{m_K (1 - m_l^2/ m_K^2)^2}{m_\pi (1 - m_l^2/ m_\pi^2)^2} \left[ 1 + \frac{\alpha}{\pi}(C_K - C_\pi) \right]
\end{equation}
The decay rates $\Gamma$ and masses are well-determined from experiment. The last factor (in brackets) accounts for radiative electroweak corrections, but it contributes little to the calculation due to the factor of $\alpha$.

The pseudoscalar decay constants themselves are defined as follows,
\begin{equation}
\langle 0 | \overline{d} \gamma_\mu \gamma_5 u | \pi^+(p) \rangle = i p_\mu f_{\pi^+}
\qquad 
\langle 0 | \overline{s} \gamma_\mu \gamma_5 u | K^+(p) \rangle = i p_\mu f_{K^+} \, .
\end{equation}
That is, they are related to the expectation value for the respective pseudoscalar particle to return to the (QCD) vacuum, which occurs by the action of its antiparticle on the state. This particular combination of gamma matrices ensures the antiparticle is a pseudoscalar also.

\subsection{As a Benchmark Calculation for the Lattice Action}


\section{Fit Functions} \label{Fit Functions}

In general, our fits are of the form
\begin{equation}
\left(\frac{F_K}{F_\pi}\right)_\text{lattice} = \left(\frac{F_K}{F_\pi}\right)_\text{model}^{(n_V)} +
\delta\left(\frac{F_K}{F_\pi}\right)_\text{NNLO} +
\delta\left(\frac{F_K}{F_\pi}\right)_\text{semi-NNLO} +
\delta\left(\frac{F_K}{F_\pi}\right)_\text{NNNLO}
\end{equation}
where the $n_V$ denotes to which order we fit the finite volume effects.
\subsection{Special Functions}
For reference later in these notes, we now list the following special functions in our fits which encapsulate the finite volume dependence. The values for the $c_n$'s are given in Table \ref{tab:cN_weights}.
\begin{align}
\mathcal{I}(m) &= \frac{m^2}{(4\pi)^2} \log \left( \frac{m^2}{\mu^2} \right)
+ \frac{m^2}{4\pi^2} \sum_{|\mathbf{n}|\neq0} \frac{c_n}{mL|\mathbf{n}|} K_1(mL|\mathbf{n}|) \label{eqn:I(m)} \\
%%%
d\mathcal{I}(m) &=
\frac{1}{(4\pi)^2} + \frac{\mathcal{I}(m)}{m^2}
+\sum_{|\mathbf{n}|\neq0} \frac{c_n}{(4\pi)^2} \left[
\frac{K_1(mL|\mathbf{n}|)}{mL|\mathbf{n}|}
-K_0(mL|\mathbf{n}|)
-K_2(mL|\mathbf{n}|)\right] \\
%%%
\mathcal{K}(m,M) &= \frac{1}{M^2 - m^2} \Big[ \mathcal{I}(M) - \mathcal{I}(m) \Big] \\
%%%
\mathcal{K}_{21}(m,M) &=
\frac{1}{(M^2 - m^2)^2} \Big[ \mathcal{I}(M) - \mathcal{I}(m) \Big]
-\frac{1}{M^2 - m^2} d\mathcal{I}(m) \\
%%%
\mathcal{K}(m_1,m_2,m_3) &= \frac{1}{m_1^2 - m_2^2}\frac{1}{m_1^2-m_3^2} \mathcal{I}(m_1)
+\frac{1}{m_2^2 - m_1^2} \frac{1}{m_2^2 - m_3^2} \mathcal{I}(m_2)
\nonumber\\&\phantom{=}
+\frac{1}{m_3^2 - m_1^2} \frac{1}{m_3^2 - m_2^2} \mathcal{I}(m_3)
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%
% cN table
\begin{table}
	\begin{ruledtabular}
		\begin{tabular}{c|cccccccccc}
			$|\mathbf{n}|$& 1 & $\sqrt{2}$& $\sqrt{3}$& $\sqrt{4}$& $\sqrt{5}$& $\sqrt{6}$& $\sqrt{7}$& $\sqrt{8}$& $\sqrt{9}$& $\sqrt{10}$\\
			\hline
			$c_n$& 6&12& 8& 6& 24& 24& 0& 12& 30& 24
		\end{tabular}
	\end{ruledtabular}
	\caption{\label{tab:cN_weights}
		Finite volume weight factors for the first few finite volume modes.
	}
\end{table}



\subsection{NLO chiral extrapolation formulae}

In these expressions, the $\eta$ meson mass can be approximated with the $SU(3)$ Gell-Mann--Okubo formula
\begin{equation}
m_\eta^2 = \frac{4}{3} m_K^2 - \frac{1}{3}m_\pi^2\, .
\end{equation}
The $X$ mass appearing in the MA formulae is
\begin{equation}
m_X^2 = m_\eta + a^2 \Delta_{\rm I}
\end{equation}
where $a^2 \Delta_{\rm I}$ is the taste-identity mass splitting which MILC has determined~\cite{Bazavov:2012xda}.

The mixed meson masses are given by
\begin{equation}
m_{val,sea}^2 = \frac{1}{2}m_{val,val}^2 + \frac{1}{2}m_{sea,sea,5}^2 + a^2 \Delta_{\rm Mix}
\simeq m_{val,val}^2 + a^2 \Delta_{\rm Mix}\, .
\end{equation}
For brevity, we label a quark $j$ for sea-up, $u$ for valence-up, $r$ for sea-strange, and $s$ for valence-strange.

Given the quark mass tuning we have done, at LO in MA EFT~\cite{Chen:2006wf}, all partial quenching parameters are given by the taste-identity splitting
\begin{equation}
\Delta_{rs}^2 = \Delta_{ju}^2 = a^2 \Delta_{\rm I}\, .
\end{equation}

We can plot the splitting over flavors and pion masses, and see how well this LO relation holds.  We will also fit using the full on-shell masses as they appear in the MA formula as well as use an average mixed-meson mass splitting, $a^2 \Delta_{\rm mix}$, averaged over the flavors and ensembles (possibly replace the average with extrapolation).





\subsection{Models}
In the following descriptions of the models, we make use of the definitions
\begin{equation}
\epsilon_\pi^2 = \frac{m_\pi^2}{\Lambda_\chi^2} \qquad
\epsilon_K^2 = \frac{m_K^2}{\Lambda_\chi^2} \qquad
\epsilon_a^2 = \frac{a^2}{16 \pi ^2\omega_0^2} \qquad
\end{equation}
where we set $\Lambda_\chi^2$ to $F_\pi^2$, $F_K^2$, or $F_\pi F_K$.

\subsubsection{NLO MA-ratio}
For these fits, we will do
\begin{equation}
\left(\frac{F_K}{F_\pi}\right)_\text{MA-ratio} = \frac{F_K^\text{nlo}}{F_\pi^\text{nlo}}
\end{equation}
where
\begin{align}
\frac{F_\pi^{\rm nlo}}{F_0} &= 1
- \frac{\mathcal{I}(m_{ju})}{F^2}
-\frac{\mathcal{I}(m_{ru})}{2F^2}
+4 \epsilon_\pi^2 (4\pi)^2 (L_4 + L_5)
+8 \epsilon_K^2 (4\pi)^2 L_4
\end{align}

\begin{align}
\frac{F_K^{\rm nlo}}{F_0} &= 1
-\frac{\mathcal{I}(m_{ju})}{2F^2}
+\frac{\mathcal{I}(m_\pi)}{8F^2}
-\frac{\mathcal{I}(m_{ru})}{4F^2}
-\frac{\mathcal{I}(m_{sj})}{2F^2}
-\frac{\mathcal{I}(m_{rs})}{4F^2}
+\frac{\mathcal{I}(m_{ss})}{4F^2}
-\frac{3\mathcal{I}(m_X)}{8F^2}
\nonumber\\&\phantom{=}
+4\epsilon_\pi^2 (4 \pi)^2 L_4 + 4\epsilon_K^2 (4 \pi)^2  (L_5 + 2L_4)
\nonumber\\&\phantom{=}
+\Delta_{ju}^2 \left[ -\frac{d\mathcal{I}(m_\pi)}{8F^2} + \frac{\mathcal{K(}m_\pi,m_X)}{4F^2} \right]
-\Delta_{ju}^4 \frac{\mathcal{K}_{21}(m_\pi,m_X)}{24 F^2}
\nonumber\\&\phantom{=}
+\Delta_{ju}^2\Delta_{rs}^2 \left[ \frac{\mathcal{K}_{21}(m_{ss},m_X)}{12F^2}
- \frac{\mathcal{K}(m_\pi, m_{ss}, m_X)}{6F^2} \right]
\nonumber\\&\phantom{=}
+\Delta_{rs}^2 \left[
\frac{\mathcal{K}(m_{ss},m_X)}{4F^2}
-\frac{\mathcal{K}_{21}(m_{ss},m_X) m_K^2}{6F^2}
+\frac{\mathcal{K}_{21}(m_{ss},m_X) m_\pi^2}{6F^2}
\right]
\end{align}


\subsubsection{NLO MA (taylor-expanded ratio)}
For these fits,

\begin{align}\label{eq:fkfpi_ma}
\left(\frac{F_K}{F_\pi}\right)_\text{MA} &= 1
+\frac{\mathcal{I}(m_{ju})}{2F^2}
+\frac{\mathcal{I}(m_\pi)}{8F^2}
+\frac{\mathcal{I}(m_{ru})}{4F^2}
-\frac{\mathcal{I}(m_{sj})}{2F^2}
+\frac{\mathcal{I}(m_{ss})}{4F^2}
-\frac{\mathcal{I}(m_{rs})}{4F^2}
-\frac{3\mathcal{I}(m_X)}{8F^2}
\nonumber\\&\phantom{=}
+\Delta_{ju}^2 \left[ -\frac{d\mathcal{I}(m_\pi)}{8F^2} + \frac{\mathcal{K(}m_\pi,m_X)}{4F^2} \right]
-\Delta_{ju}^4 \frac{\mathcal{K}_{21}(m_\pi,m_X)}{24 F^2}
\nonumber\\&\phantom{=}
+\Delta_{ju}^2\Delta_{rs}^2 \left[ \frac{\mathcal{K}_{21}(m_{ss},m_X)}{12F^2}
-\frac{\mathcal{K}(m_\pi, m_{ss}, m_X)}{6F^2}
 \right]
\nonumber\\&\phantom{=}
+\Delta_{rs}^2 \left[
\frac{\mathcal{K}(m_{ss},m_X)}{4F^2}
-\frac{\mathcal{K}_{21}(m_{ss},m_X) m_K^2}{6F^2}
+\frac{\mathcal{K}_{21}(m_{ss},m_X) m_\pi^2}{6F^2}
\right]
\nonumber\\&\phantom{=}
+ 4 (4\pi)^2 L_5 \frac{m_K^2 - m_\pi^2}{(4\pi F)^2}
\end{align}

\subsubsection{NLO $\chi$PT-ratio}
For these fits, we will do
\begin{equation}
\left(\frac{F_K}{F_\pi}\right)_\text{$\chi$PT-ratio} = \frac{F_K^{\rm nlo}}{F_\pi^{\rm nlo}}
\end{equation}
where
\begin{align}
\frac{F_\pi^{\rm nlo}}{F_0} &= 1
- \frac{\mathcal{I}(m_\pi)}{F^2}
-\frac{1}{2}\frac{\mathcal{I}(m_K)}{F^2}
+4 \epsilon_\pi^2 (4\pi)^2 (L_4 + L_5)
+8 \epsilon_K^2 (4\pi)^2 L_4 \, , \\
\frac{F_K^{\rm nlo}}{F_0} &= 1
-\frac{3}{8}\frac{\mathcal{I}(m_\pi)}{F^2}
-\frac{3}{4}\frac{\mathcal{I}(m_K)}{F^2}
-\frac{3\mathcal{I}(m_\eta)}{8F^2}
+4\epsilon_\pi^2 (4 \pi)^2  L_4 + 4\epsilon_K^2 (4 \pi)^2  (L_5 + 2L_4)
\end{align}


\subsubsection{NLO $\chi$PT (taylor-expanded ratio)}
For these fits,
\begin{align}\label{eq:fkfpi_chpt}
\left(\frac{F_K}{F_\pi}\right)_\text{$\chi$PT} &= 1
+\frac{5}{8} \frac{\mathcal{I}(m_\pi)}{F^2}
-\frac{1}{4} \frac{\mathcal{I}(m_K)}{F^2}
-\frac{3}{8} \frac{\mathcal{I}(m_\eta)}{F^2}
%\nonumber\\&\phantom{=}
+4(\epsilon_K^2 - \epsilon_\pi^2) (4\pi)^2 L_5
%\nonumber\\&\phantom{=}
+ \delta_{c.t.}^{\rm NNLO}
\end{align}
A less refined variant of this equation is given in (17) of \cite{Berkowitz:2017opd}.


\subsection{Corrections}

\subsubsection{NNLO \& NNNLO counterterms}
The NNLO and NNNLO counterterms are formed by taking powers of $\epsilon^2_\xi$ ($\xi = K, \pi, a$), along with $(\epsilon_K^2 - \epsilon_\pi^2)$ (which ensures $F_K / F_\pi$ tends to 1 in the chiral limit), to the desired order. For NNLO, we take one power of $\epsilon^2_\xi$ and one power of $(\epsilon_K^2 - \epsilon_\pi^2)$.
\begin{equation}
\delta\left(\frac{F_K}{F_\pi}\right)_\text{NNLO} = \bigg[
\epsilon_a^2  A_{a}
+\epsilon_K^2  A_{K}
+\epsilon_\pi^2  A_{\pi}
\bigg] (\epsilon_K^2 - \epsilon_\pi^2)
\end{equation}
One might expect a term like $(\epsilon_K^2 - \epsilon_\pi^2)^2 A_{\chi}$ to show up in the NNLO expansion; however, this term is already covered by $[\epsilon_K^2  A_{K}+\epsilon_\pi^2  A_{\pi}] (\epsilon_K^2 - \epsilon_\pi^2)$.

In fact, the pure NNLO counterterm (sans lattice spacing) was worked out in  \cite{Ananthanarayan:2017qmx}. We have that
\begin{align} \label{eqn:C_j_defn}
\delta\left(\frac{F_K}{F_\pi}\right)_{\text{NNLO} / \{a^2 \}}
&= (4 \pi)^2 \left(\epsilon_K^2 - \epsilon_\pi^2\right) \\
&\times \Bigg\{ 
8 (4 \pi)^2 \big[ 2 \left(C_{14} + C_{15}\right) \epsilon_K^2 + \left( C_{15} + 2 C_{17} \right) \epsilon_\pi^2 \big] \nonumber \\
&\phantom{= \Bigg\}} +  \left[ 8 (4 \pi)^2 L_5  \big( 8 L_4 + 3L_5 - 16 L_6 -8L_8 \big)
-2 L_1 - L_2 - \frac{1}{18} L_3 + \frac{4}{3} L_5 - 16 L_7 - 8 L_8
\right] \epsilon_K^2 \nonumber \\
&\phantom{= \Bigg\}} +  \left[ 8 (4 \pi)^2  L_5  \big( 4 L_4 + 5 L_5 - 8 L_6 - 8 L_8 \big)
-2 L_1 - L_2 - \frac{5}{18} L_3 - \frac{4}{3} L_5 + 16 L_7 + 8 L_8
\right] \epsilon_\pi^2 \nonumber 
\Bigg\} \, .
\end{align}
When we include the single log terms in our fit (see the next section), we determine the $L_i$ LECs; however, we never determine the $C_{ij}$ constants in our fits. Therefore when we include single log terms, we fit the full counterterm, with $A_K$ and $A_\pi$ absorbing the $C_{ij}$ dependence. That is,
\begin{align}
&A_K = 16 (4 \pi)^4 (C_{14} + C_{15}) \qquad A_\pi = 8 (4 \pi)^4 (C_{15} + 2 C_{17}) &&  \text{(only if including single log terms)}
\end{align}
When we don't include the single log terms, then attempting to determine all the LECs in \eqref{eqn:C_j_defn} is futile. In this case, we let $(\epsilon_K^2  A_{K} +\epsilon_\pi^2  A_{\pi}) (\epsilon_K^2 - \epsilon_\pi^2)$ stand-in for the entirety of \eqref{eqn:C_j_defn}.

For NNNLO, we take two powers of $\epsilon^2_\xi$ and one power of $(\epsilon_K^2 - \epsilon_\pi^2)$ (and vice-versa).
\begin{align}
\delta\left(\frac{F_K}{F_\pi}\right)_\text{NNNLO} &= \bigg[
\epsilon_a^4  A_{a, a} + \epsilon_a^2 \epsilon_K^2  A_{a, K} + \epsilon_a^2 \epsilon_\pi^2  A_{a, \pi} \\ \nonumber
&\phantom{[ =} + \epsilon_K^4  A_{K, K} + \epsilon_K^2 \epsilon_\pi^2  A_{K, \pi} \\ \nonumber
&\phantom{[ =} + \epsilon_\pi^4  A_{\pi, \pi} \bigg] (\epsilon_K^2 - \epsilon_\pi^2)
\end{align}

Notice that the lattice spacing and $am_\xi$ ($\xi \in \{\pi, K, \eta\}$) corrections are included in these counterterms. For example, the term $\epsilon^2_a (\epsilon^2_K - \epsilon^2_\pi)$ accounts for the lowest order lattice spacing correction. Further note that our choice of action (Domain wall) means that the theory will automatically be $\mathcal{O}(a)$ improved~\cite{Berkowitz:2017opd}, hence the lack of terms at that order.

\subsubsection{Semi-NNLO counterterms}
Finally, there are counterterms that lies between NNLO and NNNLO. These come in three varieties: 
\begin{enumerate}
	\item semi-NNLO lattice spacing corrections
	\item single log terms
	\item log-squared terms
\end{enumerate}
As it turns out, the lattice space discretization corrections cannot be exactly accounted for by a purely polynomial expansion: there remains a semi-NNLO counterterm that goes as $\sim \epsilon_a^2 (\epsilon_K^2 - \epsilon_\pi^2) \log(a)$. Since $\alpha_S \sim \log(a)$, we have the first semi-NNLO correction:
\begin{equation}
\delta\left(\frac{F_K}{F_\pi}\right)_{\alpha_S} =
A_{\log a} \alpha_S \, \epsilon_a^2  (\epsilon_K^2 - \epsilon_\pi^2) \, .
\end{equation}
Note that we can't subsume $\alpha_S$ into $A_{\log a}$ since the former varies by ensemble. 

Next we consider the single log terms, which account for loop-corrections in the chiral expansion. These were also worked out in \cite{Ananthanarayan:2017qmx}. For convenience, we define
\begin{align}
\hat C^r_1 
&= - \left[ \frac{7}{9} + \frac{11}{2} (4 \pi)^2 L_5 \right] \epsilon_\pi^2 \epsilon_K^2
- \left[ \frac{113}{72} + (4 \pi)^2 \left( 
4 L_1 + 10 L_2 + \frac{13}{2} L_3 - \frac{21}{2} L_5
\right) \right] \epsilon_\pi^4\\
\hat C^r_2 
&=   \left[ \frac{53}{96} + (4 \pi)^2 \left( 
4 L_1 + 10 L_2 + 5 L_3 - 5 L_5
\right) \right] \epsilon_K^4
+ \left[ \frac{209}{144} + 3 (4 \pi)^2 L_5 \right] \epsilon_\pi^2 \epsilon_K^2 \\
\hat C^r_3
&=   \left[ \frac{13}{18} + (4 \pi)^2 \left( 
\frac 83 L_3 - \frac 23 L_5 -16 L_7 - 8 L_8
\right) \right] \epsilon_K^4 \\
&\qquad 
- \left[ \frac{4}{9} + 3 (4 \pi)^2 \left(
\frac 43 L_3 + \frac {25}{6} L_5 -32 L_7 - 16 L_8
\right) \right] \epsilon_\pi^2 \epsilon_K^2 \nonumber \\
&\qquad 
+ \left[ \frac{19}{288} + (4 \pi)^2 \left( 
\frac 16 L_3 + \frac{11}{6} L_5 -16 L_7 - 8 L_8
\right) \right] \epsilon_\pi^4 \nonumber
\end{align}
Now we can write the second semi-NNLO contribution.
\begin{equation}
\delta\left(\frac{F_K}{F_\pi}\right)_\text{log-NNLO} =
C_1 \log \epsilon_\pi^2
+ C_2  \log \epsilon_K^2
+ C_3 \log \epsilon_\eta^2
\end{equation}

Finally we include the log-squared two-loop corrections, which again are taken from \cite{Ananthanarayan:2017qmx}.  Let us define 
\begin{equation}
\begin{aligned}[c]
\hat K^r_1  &=  \frac{11}{24} \epsilon_\pi^2 \epsilon_K^2 - \frac{131}{192} \epsilon_\pi^4 \\
\hat K^r_3 & = \frac{13}{24} \epsilon_\pi^2 \epsilon_K^2 + \frac{59}{96} \epsilon_\pi^4 \qquad \\
\hat K^r_5  &= -\frac{163}{144}  \epsilon_K^4 - \frac{67}{288} \epsilon_\pi^2 \epsilon_K^2 + \frac{3}{32} \epsilon_\pi^4 \qquad
\end{aligned}
\qquad
\begin{aligned}[c]
\hat K^r_2 &= -\frac{41}{96} \epsilon_\pi^2 \epsilon_K^2 - \frac{3}{32} \epsilon_\pi^4  \\
\hat K^r_4 &= \frac{17}{36} \epsilon_K^4 + \frac{7}{144} \epsilon_\pi^2 \epsilon_K^2 \\
\hat K^r_6 &= \frac{241}{288}  \epsilon_K^4 - \frac{13}{72} \epsilon_\pi^2 \epsilon_K^2 - \frac{61}{192}  \epsilon_\pi^4 \qquad
\end{aligned}
\end{equation}
Then
\begin{align}
\delta\left(\frac{F_K}{F_\pi}\right)_\text{log-log-NNLO} &=
 \hat K^r_1 \left( \log \epsilon_\pi^2 \right)^2
 + \hat K^r_2 \log \epsilon_\pi^2  \log \epsilon_K^2
 + \hat K^r_3 \log \epsilon_\pi^2 \log \epsilon_\eta^2 \\
 &+\hat K^r_4 \left( \log \epsilon_K^2 \right)^2
 +\hat K^r_5 \log \epsilon_K^2  \log \epsilon_\eta^2
  +\hat K^r_6 \left( \log \epsilon_\eta^2 \right)^2 \nonumber
\end{align}

In totality, the semi-NNLO terms are
\begin{equation}
\delta\left(\frac{F_K}{F_\pi}\right)_{\text{semi-NNLO}} =
\delta\left(\frac{F_K}{F_\pi}\right)_{\alpha_S}
+ \delta\left(\frac{F_K}{F_\pi}\right)_{\text{log-NNLO}}
+ \delta\left(\frac{F_K}{F_\pi}\right)_{\text{log-log-NNLO}}\, .
\end{equation}


\subsubsection{ SU(2) isospin breaking}
The breaking of SU(2) isospin symmetry is characterized by
\begin{equation}
\delta_{\text{SU(2)}} = \sqrt{3} \epsilon_\text{SU(2)} \left[
-\frac43 (F_K / F_\pi-1)
+\frac{4}{3(4 \pi F)^2} \left( m_K^2 - m_\pi^2 -m_\pi^2 \log \frac{m_k^2}{m_\pi^2} \right)
\right]
\end{equation}
where $\epsilon_\text{SU(2)} = \sqrt{3}/(4R)$, $R=35.7(2.6)$ per FLAG, the masses are the physical values, and $F_K/F_\pi$ is the fitted value extrapolated to the physical point. With $\delta_{\text{SU(2)}}$ in hand, we can compare our value of $F_K/F_\pi$ determined on the lattice to the corrected charged ratio $F^\pm_K/F^\pm_\pi$ through
\begin{equation}
\frac{F^\pm_K}{F^\pm_\pi} = \frac{F_K}{F_\pi} \sqrt{1+ \delta_{\text{SU(2)}}} \, .
\end{equation}
The corrected charge ratio $F^\pm_K/F^\pm_\pi$ is the value reported by FLAG.

%%%%%%%%%%%%%%%%%%
%%%%% FIT STRATEGY
%%%%%%%%%%%%%%%%%%
\section{Fit Strategy}

From inspections, one sees that the fit depends on the pion, kaon, and mixed meson masses; the taste-identity splitting $\Delta_{rs}^2 = \Delta_{ju}^2 = a^2 \Delta_\text{I}$; the lattice spacing $a$ (or its proxy $a/w_0$); and the pion and kaon decay constants. First we briefly explain how these quantities were determined, then how we can use them to determine $F_K / F_\pi$ at the physical point.


\subsection{Meson masses}
The meson masses are determined by fitting the spectral decomposition of the meson two-point correlation functions.
\begin{equation}
C(t) = \sum_n Z^{(PS)}_{n} Z^{(SS)}_{n} \left( e^{-E_n t} + e^{-E_n (T-t)} \right)
\label{eqn:meson-correlation-fcn}
\end{equation}

Usually it's sufficient to fit only a single exponential, so we only need to choose the start and end times for our fit. Further, by symmetrically fitting the interval $[t, T - t]$, we reduce these three fit choices to only one -- determining the start time.

Once the mass has been determined over the full ensemble (boot0), the correlation function is resampled $N$ times to form $N$ bootstrap resamples. These bootstrap resamples are then fit over the same time range as the full ensemble and the results are saved, giving us a list of masses for bootstrapping.

\subsection{Taste-identity splitting}
As previously stated, this quantity has been determined by MILC~\cite{Bazavov:2012xda}.

\subsection{Wilson flow scale $\omega_0$}
The Wilson flow-derived quantity $\omega_0$ allows for high-precision scale setting~\cite{Borsanyi:2012zs}. In general, one can measure the lattice spacing by comparing the lattice value of some (dimensionful) observable to its experimental value, eg,
\begin{equation}
a = \frac{(a m_\Omega)^\text{latt}}{m_\Omega^\text{exp}}
\end{equation}
which can be converted to physical units by multiplying by $\hbar c$ (ie, $a_\text{phys} = a \hbar c$). Similarly, one can determine $\omega_0$ by measuring
\begin{equation}
w_0 = \frac{(w_0 m_\Omega)^\text{latt}}{m_\Omega^\text{exp}} \, ,
\end{equation}
a task currently underway in another project.  {\color{red} (Is this right?)} In particular, given the following observable
\begin{equation}
W(t) \equiv t \frac{d}{dt} \Big[ t^2 \langle E(t) \rangle \Big] \, ,
\end{equation}
the scale $w_0$ is the value such that
\begin{equation}
W(t) \Big|_{t=w_0^2} = 0.3 \, .
\end{equation}

For the purpose of this project, we take $w_0 = 0.175(10)$, which is a conservative estimate taken from current progress on scale setting. We only use $w_0$ to make graphs -- it has no bearing on our final result (the extrapolation of $F^\pm_K/F^\pm_\pi$ to the physical point).

\begin{figure}
	\includegraphicsifexists[width=0.75\textwidth]{./../figs/w0_comparison.pdf}
	\caption{Current results on scale setting. Notice that our conservative choice for $w_0$ contains all the models in the figure and then some.}
\end{figure}

\subsection{The pion and kaon decay constants, $F_K$ and $F_\pi$}
The fit functions for the pseudoscalar decay constants can be derived using 5D Ward Identities, thereby relating the decay constants to correlation functions \cite{Berkowitz:2017opd}. With some work, we get the following expression
\begin{equation}
F_{q_1 q_2} = Z^{(PS)}_{q_1 q_2}\frac{m_{q_1} + m_{q_2} + m^{(res)}_{q_1} + m^{(res)}_{q_2} }{\sqrt[\leftroot{-3}\uproot{3}3]{E_{q_1 q_2}}}
\end{equation}
where $m^{(res)}_q$ is the residual mass of quark $q$ (which characterizes the breaking of chiral symmetry) and $E_{q_1 q_2}$ is the ground state energy of the meson $(q_1 q_2)$, as determined in \eqref{eqn:meson-correlation-fcn}.



\section{The Weeds}
The actual fit here is performed in lattice units, not physical units, which is possible since the ratio $F_K / F\pi$ is dimensionless.

\subsection{Model Average}
Per section \ref{Fit Functions}, we see that our analysis includes numerous possible models: we have four different base models, three choices for $\Lambda_\chi$, counterterms to three orders, log-squared and semi-log terms, and up to ten volume corrections. Our model average is determined by weighing included models by their Bayes factor, as will be explained shortly. However, even without explaining this weighing process, it should be clear that fits having a comparatively small Bayes factor will contribute negligibly to the fit. In particular, the NLO fits have Bayes factors many orders of magnitude smaller than the NNLO fits. We therefore exclude the NLO fits from our analysis.

In the other direction, we exclude the NNNLO fits. These fits can have much better Bayes factors (comparable to the NNLO fits), but the fits are also highly sensitive to choice of prior, which we can only weakly determine (see subsection \ref{Selection of Prior} below). We therefore exclude the NNNLO fits due to the lack of a robust measure by which we can judge whether the priors have been set appropriately.

What remains are the models we include in our average: fits with the four base models, with the three choices for $\Lambda_\chi$, with the NNLO counterms, with or without the semi-log term, with or without the log-squared term, and with or without finite volume corrections (which, for the lattermost option, means either including the ten volume corrections or none at all). In totality, this gives us 96 different models to average over.

Our model average is performed under a Bayesian framework, following the procedure described in \cite{Chang_2018}. Suppose we are interested in estimating the posterior distribution of $Y = F_K / F_\pi$, ie, $P(Y|D)$. To that end, we must marginalize over the different models $M_k$. 
\begin{equation}
P(Y|D) = \sum_k P(Y | M_k, D) P(M_k | D)
\end{equation}
Here $P(Y | M_k, D)$ is the distribution of $Y$ for a given model $M_k$ and dataset $D$, while $P(M_k | D)$ is the posterior distribution of $M_k$ given $D$. The latter can be written, in accordance to Bayes theorem, as 
\begin{equation}
P(M_k | D) = \frac{P(D | M_k) P(M_k)}{\sum_l P(D | M_l) P(M_l)} \, .
\end{equation}
We can be more explicit with what the latter is in the context of our fits. First, mind that we are \emph{a priori} agnostic in our choice of $M_k$. We thus take the distribution $P(M_k)$ to be uniform over the different models. We calculate $P(D | M_l)$ by marginalizing over the parameters (LECs) in our fits:
\begin{equation}
P(D | M_k) = \int \prod_j \text{d} \theta_j^{(k)} \,  P(D | \theta_j^{(k)}, M_k) P(\theta_j^{(k)} | M_k) \, .
\end{equation}
After marginalization, $P(D | M_k)$ is just a number. Specifically, it is the Bayes factor of $M_k$: $P(D | M_k) = \exp(\texttt{logGBF})_{M_k}$. Thus
\begin{equation}
P(M_k | D) = \frac{\exp(\texttt{logGBF})_{M_k}}{K \sum_l \exp(\texttt{logGBF})_{M_l}}
\end{equation}
with $K = 96$ the number of models included in our average.

Now we can estimate the mean and variance of $Y$.
\begin{align}
\text{E}[Y] &= \sum_k \text{E}[Y | M_k] \, P(M_k | D)  \\
\text{Var}[Y] &= \sum_k \text{Var}[Y | M_k] P(M_k | D)
+ \left( \sum_k \text{E}^2[Y | M_k] \, P(M_k | D)\right) 
- \text{E}^2[Y | D] \nonumber
\end{align}

\subsection{Selection of Prior} \label{Selection of Prior}

\begin{table}[]
	\begin{tabular}{l|llc}
		& LEC          & Term                                          & \begin{tabular}[c]{@{}l@{}}Order at \\ Phys Point\end{tabular} \\ \hline\hline
		\multirow{3}{*}{NNLO}  & $A_a$        & $\epsilon^2_a \epsilon^2_\chi$                & 0                                                              \\
		& $A_K$        & $\epsilon^2_K \epsilon^2_\chi$                & $\sim10^{-2}$                                                  \\
		& $A_\pi$      & $\epsilon^2_\pi \epsilon^2_\chi$              & $\sim10^{-3}$                                                  \\ \hline
		\multirow{6}{*}{NNNLO} & $A_{aa}$     & $\epsilon^4_a \epsilon^2_\chi$                & 0                                                              \\
		& $A_{a\pi}$   & $\epsilon^2_a \epsilon^2_\pi \epsilon^2_\chi$ & 0                                                              \\
		& $A_{aK}$     & $\epsilon^2_a \epsilon^2_K \epsilon^2_\chi$   & 0                                                              \\
		& $A_{KK}$     & $\epsilon^4_K \epsilon^2_\chi$                & $\sim 10^{-3}$                                                 \\
		& $A_{K\pi}$   & $\epsilon^2_K \epsilon^2_\pi \epsilon^2_\chi$ & $\sim 10^{-4}$                                                 \\
		& $A_{\pi\pi}$ & $\epsilon^2_K \epsilon^2_\pi \epsilon^2_\chi$ & $\sim 10^{-5}$
	\end{tabular}
	\caption{Contributions from each LEC at the physical point. Here we define $\epsilon^2_\chi = (\epsilon^2_K -\epsilon^2_\pi)$, which ensures $F_K/F_\pi \rightarrow 1$ in the SU(3) isospin limit.}
\end{table}

\begin{enumerate}
	\item At NLO, the most naive guess is that the LECs $L_4$ and $L_5$ should be order 1. Running the NLO fit a few times, we quickly discover that these LECs are a few orders of magnitude smaller. Therefore, refining our priors for $L_4$ and $L_5$, we set \texttt{p[`L\_4'] = 0(0.001)} and \texttt{p[`L\_5'] = 0(0.001)}. In practice this width extends about an order of magnitude outside our results for $L_4$ and $L_5$, regardless of NLO model chosen.

	\item For the next higher order (NNLO) fits, we used \texttt{lsqfit.empbayes\_fit} to determine the priors for the NNLO LECs, which searches the parameter space for priors such that the Bayes Factor is maximized. While performing this search, we constrain the NNLO LECs such that \texttt{p[`A\_k'] = p[`A\_p']} (per chiral symmetry, these LECs should be roughly the same size) and such that \texttt{p[`A\_a'] = p[`A\_loga']} (we assume the lattice spacing corrections come at the same order).
\end{enumerate}

\subsection{Effect of NNLO LECs on fit convergence}
We compare the effect of adding each NNLO LEC to the fit as well as the effect of chaining the fits. The priors for the NNLO LECs were set in accordance to the method described earlier in these notes, unless the figure corresponds to not chaining the fits, in which case that step is skipped.

\foreach \model in {ma, ma-taylor, xpt, xpt-taylor}
{
	\begin{figure}[H]
		\begin{subfigure}[t]{0.45\textwidth}
			\includegraphicsifexists[width=\textwidth]{"./../tmp/exclude_lecs/\model_chained-True_exclude-n2lo".pdf}
		\end{subfigure}
		~
		\begin{subfigure}[t]{0.45\textwidth}
			\includegraphicsifexists[width=\textwidth]{"./../tmp/exclude_lecs/\model_chained-False_exclude-n2lo".pdf}
		\end{subfigure}
	\caption{Effect of individually including NNLO LECs for model \texttt{\model}. The topmost (non-FLAG) result is equivalent to the NLO fit; the bottommost is equivalent to the NNLO fit. See table \ref{\model-prior} for prior.}
	\end{figure}
}

\subsection{Shifting lattice data to physical point}
Notice that the fit of $F_K/F_\pi$ depends on multiple input parameters: $\epsilon^2_\pi$, $w_0$, $a$, etc; that is, we are fitting a many-dimensional surface, so in order to plot $F_k/F_\pi$ vs some parameter, we must carefully take a slice of that surface. In our case, we fit $F_K / F_\pi$ at the physical point with the exception of some input parameters, which we allow to vary.

Of course, our set of data is not at the physical point, so we must account for this when making these plots. We therefore ``shift" the lattice data to the physical point (while allowing a single parameter to vary) using the following heuristic. Let $\{p_j\} = \{\epsilon^2_\pi, w_0, a, \cdots\}$ be the set of input parameters in the fit for some ensemble and $\{p^*_j\}$ the physical value of these parameters. Now suppose we are interested in the dependence of $F_K / F_\pi$ on some subset of the parameters $\{q_k\}$. Then to shift the data to the physical point without shifting $\{q_k\}$, we calculate
\begin{equation}
\left( \frac{F_K}{F_\pi} \right)_\text{shifted data} =
\left( \frac{F_K}{F_\pi} \right)_\text{data}
+ \left( \frac{F_K}{F_\pi} \right) \bigg|_{\text{fit at } \{p^*_j, q_k\}}
- \left( \frac{F_K}{F_\pi} \right) \bigg|_{\text{fit at } \{p_j, q_k\}} \, .
\end{equation}

Alternatively, one often uses the ratio instead.

\begin{equation}
\left( \frac{F_K}{F_\pi} \right)_\text{shifted data} =
\left( \frac{F_K}{F_\pi} \right)_\text{data}
\Bigg[ \left( \frac{F_K}{F_\pi} \right) \bigg|_{\text{fit at } \{p^*_j, q_k\}}
\bigg/ \left( \frac{F_K}{F_\pi} \right) \bigg|_{\text{fit at } \{p_j, q_k\}} \, \Bigg] .
\end{equation}

I haven't noticed a visible difference in using one versus the other.

\section{Fit Results}
Here we present the results for each of the fits.

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/comparison_fits.pdf}
	\caption{Extrapolations of $F^\pm_K/F^\pm_\pi$ to the physical point for the various models, with the FLAG average overlaid.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/comparison_delta_su2.pdf}
	\caption{Extrapolations of $\delta_{\text{SU(2)}}$ to the physical point for the various models.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/histogram_fit.pdf}
	\caption{Distribution of $F^\pm_K/F^\pm_\pi$, weighed by Bayes factor.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/histogram_delta_su2.pdf}
	\caption{Distribution of $\delta_{\text{SU(2)}}$, weighed by Bayes factor.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/all_fits_vs_latt_spacing.pdf}
	\caption{Plotting $F^\pm_K/F^\pm_\pi$ as a function of lattice spacing, fixing the other parameters at the physical point. Every model in the analysis is included in this graphic, but the amount of transparency allotted to a given model is inversely proportional to the Bayes factor of that model. Therefore models that contribute more heavily are more opaque than models that contribute negligibly, the latter of which might be invisible on the plot.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/all_fits_vs_mpi.pdf}
	\caption{Plotting $F^\pm_K/F^\pm_\pi$ as a function of $m_\pi$, fixing the other parameters at the physical point.. Every model in the analysis is included in this graphic, but the amount of transparency allotted to a given model is inversely proportional to the Bayes factor of that model. Therefore models that contribute more heavily are more opaque than models that contribute negligibly, the latter of which might be invisible on the plot.}
\end{figure}

\begin{figure}[H]
	\includegraphicsifexists[width=0.9\textwidth]{./../figs/generated/all_fits_vs_volume.pdf}
	\caption{Plotting $F^\pm_K/F^\pm_\pi$ as a function of the volume correction (varying $L$), fixing the other parameters at the physical point. Every model in the analysis is included in this graphic, but the amount of transparency allotted to a given model is inversely proportional to the Bayes factor of that model. Therefore models that contribute more heavily are more opaque than models that contribute negligibly, the latter of which might be invisible on the plot.}
\end{figure}

%\csvautotabular[respect all]{"./../results/fit"_"results".csv}
%\begin{tabular}{|l|c|}%\hline%
%	\sisetup{round-mode=places, round-precision=3}
%	fit & logGBF \\ \hline\hline
%	\csvreader[head to column names]%
%	{"./../results/fit_results".csv}{}%
%	{\\ \fit & \num{\logGBF}}%
%	\\\hline
%\end{tabular}



\appendix
\section{Physical Point Values}
The physical point values are given in Table \ref{table:phys_point_values}. The pion and kaon masses are taken from \cite{Berkowitz:2017opd} while the mass for the $\eta^\prime = (ss)$ meson is taken from \cite{Dowdall:2013rya}; however, we could have just as readily taken $m_{ss}^2 = 2 m_K^2 - m_\pi^2$ evaluated at the physical point (see Fig \ref{fig:mss}).

\begin{figure}
	\includegraphicsifexists[width=0.9\textwidth]{./../tmp/mss_vs_mk_mpi.pdf}
	\caption{Comparison of $m_{ss}^2$ and $2m_K^2 - m_\pi^2$.}
	\label{fig:mss}
\end{figure}

\begin{table}[]
	\begin{ruledtabular}
		\begin{tabular}{lll||lll||lll}
		$a/w_0$ & $L$      & $a^2 \Delta_I$ & $m_\pi$ (MeV)   & $m_K$ (MeV)     & $m_{ss}$ (MeV)   & $F_\pi$ (MeV)   & $F_K$ (MeV)      & $F_K^\pm/F_\pi^\pm$ \\
		\hline\
		0       & $\infty$ & 0              & $134.8(3)$ & $494.2(3)$& $688.5(2.2)$ & $91.9(3.5)$ & $110.38(64)$ & $1.1932(19)$       \\
		\end{tabular}
	\end{ruledtabular}
\caption{Values used when extrapolating to the physical point; $F_K^\pm/F_\pi^\pm$ is taken from FLAG (and is not used for the extrapolation).}
\label{table:phys_point_values}
\end{table}

\section{Comparison with Experiment}
The CKM matrix element $|V_{ud}|$ has been determined to an accuracy better than 0.03 \% using super-allowed nuclear beta-decays. 

\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
